<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8">
<title>阿里云 NLS 流式 ASR</title>
<style>
  body { font-family: sans-serif; max-width: 700px; margin: 40px auto; padding: 0 20px; }
  button { padding: 10px 24px; font-size: 16px; cursor: pointer; }
  #interim { color: #999; min-height: 24px; margin-top: 16px; }
  #final { margin-top: 8px; line-height: 1.8; }
  #status { font-size: 13px; color: #666; margin-top: 8px; }
</style>
</head>
<body>
<h2>阿里云 NLS 流式语音识别</h2>
<p>架构：浏览器 → 后端获取 NLS Token → 直连阿里云 WebSocket</p>
<button id="btn">开始录音</button>
<div id="status">就绪</div>
<div id="interim"></div>
<div id="final"></div>

<script>
const SERVER = 'http://localhost:3000'
let ws, audioCtx, processor, stream, recording = false
let taskId = ''

document.getElementById('btn').onclick = () => recording ? stop() : start()

function uuid() {
  return crypto.randomUUID().replace(/-/g, '')
}

async function start() {
  setStatus('获取 NLS Token...')
  const { token, appKey, error } = await fetch(`${SERVER}/token/aliyun`, { method: 'POST' }).then(r => r.json())
  if (error) return setStatus('错误: ' + error)

  // 客户端直连阿里云 NLS WebSocket，token 放在 URL 参数
  ws = new WebSocket(`wss://nls-gateway.cn-shanghai.aliyuncs.com/ws/v1?token=${token}`)
  taskId = uuid()

  ws.onopen = () => {
    // 发送 StartTranscription 指令
    ws.send(JSON.stringify({
      header: {
        message_id: uuid(),
        task_id: taskId,
        namespace: 'SpeechTranscriber',
        name: 'StartTranscription',
        appkey: appKey,
      },
      payload: {
        format: 'pcm',
        sample_rate: 16000,
        enable_intermediate_result: true,
        enable_punctuation_prediction: true,
        enable_inverse_text_normalization: true,
      },
    }))
  }

  ws.onmessage = async (e) => {
    const d = JSON.parse(e.data)
    const name = d.header?.name

    if (name === 'TranscriptionStarted') {
      setStatus('已连接，录音中...')
      await startAudio()
    } else if (name === 'TranscriptionResultChanged') {
      // 中间结果
      document.getElementById('interim').textContent = d.payload?.result || ''
    } else if (name === 'SentenceEnd') {
      // 一句话结束
      document.getElementById('final').textContent += (d.payload?.result || '') + '\n'
      document.getElementById('interim').textContent = ''
    } else if (name === 'TranscriptionCompleted') {
      setStatus('识别完成')
    }
  }

  ws.onclose = () => setStatus('连接已关闭')
  ws.onerror = () => setStatus('WebSocket 错误')

  recording = true
  document.getElementById('btn').textContent = '停止录音'
}

async function startAudio() {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  audioCtx = new AudioContext({ sampleRate: 16000 })
  const source = audioCtx.createMediaStreamSource(stream)
  processor = audioCtx.createScriptProcessor(4096, 1, 1)
  source.connect(processor)
  processor.connect(audioCtx.destination)
  processor.onaudioprocess = (e) => {
    if (ws.readyState !== WebSocket.OPEN) return
    const f32 = e.inputBuffer.getChannelData(0)
    const i16 = new Int16Array(f32.length)
    for (let i = 0; i < f32.length; i++) i16[i] = Math.max(-32768, Math.min(32767, f32[i] * 32768))
    ws.send(i16.buffer)
  }
}

function stop() {
  processor?.disconnect()
  stream?.getTracks().forEach(t => t.stop())
  audioCtx?.close()
  // 发送 StopTranscription 指令
  if (ws?.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({
      header: { message_id: uuid(), task_id: taskId, namespace: 'SpeechTranscriber', name: 'StopTranscription' },
    }))
  }
  recording = false
  document.getElementById('btn').textContent = '开始录音'
  setStatus('已停止')
}

function setStatus(msg) { document.getElementById('status').textContent = msg }
</script>
</body>
</html>
